{"cells":[{"cell_type":"markdown","metadata":{"id":"atWG72RrG_i0"},"source":["Proyecto prueba TW LATAM\n","\n","Para que este proyecto funcione se debe:\n","\n","Hacer un Git clone al repositorio https://github.com/bjofres/tw-latam-test-project.git dentro de la carpeta **My Drive\\latam-tw-test**\n","\n","Autorizar la conexión con la cuenta de Google en el drive.mount\n","\n","El Notebook ipnyb fue desarrollado y testeado en \"**Google Colab**\"\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":889,"status":"ok","timestamp":1733704826002,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"PzFf8t6MrtBe","outputId":"9452a2d4-e13b-46c9-8126-13aef1b7bc4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["IPython autoreload activated\n"]}],"source":["# Habilita la recarga automática de módulos en Jupyter Notebook.\n","# Esto mejora el flujo de trabajo de desarrollo al aplicar automáticamente los cambios realizados\n","# en los módulos importados sin necesidad de reiniciar manualmente el kernel.\n","%reload_ext autoreload\n","\n","# Configura el modo de recarga automática.\n","# La opción \"2\" asegura que todos los módulos se recarguen automáticamente después de cualquier cambio.\n","%autoreload 2\n","\n","# Mensaje de confirmación para indicar que la funcionalidad de autoreload está activa.\n","print(\"IPython autoreload activated\")"]},{"cell_type":"markdown","source":["Mount a content/drive de la cuenta de Google Drive donde almacenaremos el proyecto y la data de Tweets que trabajaremos"],"metadata":{"id":"8F73HZ7p73XL"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2721,"status":"ok","timestamp":1733704828721,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"YkaR33TpH0uO","outputId":"12b2cfcd-729b-4c75-f508-e0532dd5bc19"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Montar Google Drive\n","# En este caso no instalamos ninguna librería para Drive puesto estamos utilizando Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["Cambia el directorio de trabajo a la carpeta especificada en Google Drive.\n","Esto es útil cuando se trabaja en Google Colab para organizar proyectos y facilitar el acceso a los archivos."],"metadata":{"id":"W0Cx2A7K8mwI"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1733704828721,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"E0PPgzitHLwq","outputId":"0ed810ee-63af-443f-bb64-fbb46609a0ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/latam-tw-test/tw-latam-test-project\n"]}],"source":["cd /content/drive/My Drive/latam-tw-test/tw-latam-test-project"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7528,"status":"ok","timestamp":1733704836247,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"CzaS8pyBN-71","outputId":"1ba8db62-6669-4dff-9ad5-0a35a956d3bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: memory-profiler==0.61.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.61.0)\n","Requirement already satisfied: emoji==2.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2.14.0)\n","Requirement already satisfied: gdown==5.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.2.0)\n","Requirement already satisfied: line_profiler==4.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.2.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler==0.61.0->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (4.66.6)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==5.2.0->-r requirements.txt (line 3)) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (1.7.1)\n"]}],"source":["# Librerías necesarias\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","source":["Descarga el archivo ZIP y lo extrae para poder realizar las actividades de procesamiento de datos\n","\n","Si el archivo ya existe no lo descarga nuevamente"],"metadata":{"id":"I5hB0G4wzSaw"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1733704836446,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"2tZbFVCFJE0f","outputId":"280b8575-8c63-4a1f-e9cc-18473245fd3b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ruta completa del archivo: /content/drive/My Drive/latam-tw-test/tw-latam-test-project/tweets_extracted/farmers-protest-tweets-2021-2-4.json\n","El archivo farmers-protest-tweets-2021-2-4.json ya existe en /content/drive/My Drive/latam-tw-test/tw-latam-test-project/tweets_extracted/. No se descargará nuevamente.\n"]}],"source":["import os\n","import gdown\n","import zipfile\n","\n","# Define el directorio donde se guardará el archivo\n","file_directory = '/content/drive/My Drive/latam-tw-test/tw-latam-test-project/tweets_extracted/'\n","\n","# Define el nombre del archivo\n","file_name = 'farmers-protest-tweets-2021-2-4.json'\n","\n","# Concatenamos la ruta y el nombre del archivo\n","file_path = os.path.join(file_directory, file_name)\n","print(f\"Ruta completa del archivo: {file_path}\")\n","\n","# ID del archivo en Google Drive para descargar el archivo ZIP\n","file_id = \"1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n","\n","# URL genérica para descargar desde Google Drive\n","download_url = f\"https://drive.google.com/uc?id={file_id}\"\n","\n","# Nombre para el archivo ZIP descargado\n","zip_output = \"tweets.json.zip\"\n","\n","# Verifica si el archivo ya existe\n","if os.path.exists(file_path):\n","    print(f\"El archivo {file_name} ya existe en {file_directory}. No se descargará nuevamente.\")\n","else:\n","    # Si el archivo no existe, descarga y descomprime el archivo ZIP\n","    try:\n","        # Descargar el archivo ZIP\n","        print(f\"Descargando {zip_output} desde Google Drive...\")\n","        gdown.download(download_url, zip_output, quiet=False)\n","\n","        # Descomprimir el archivo ZIP\n","        with zipfile.ZipFile(zip_output, 'r') as zip_ref:\n","            zip_ref.extractall(file_directory)\n","\n","        print(f\"Archivo descomprimido en la carpeta {file_directory}.\")\n","    except Exception as e:\n","        print(f\"Error al descargar o descomprimir el archivo: {e}\")\n"]},{"cell_type":"markdown","metadata":{"id":"tW9HLdqpG_i0"},"source":["Se importan los modulos python junto con sus funciones  "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"9bZ-GGURMeaA","executionInfo":{"status":"ok","timestamp":1733704837543,"user_tz":180,"elapsed":1098,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"}}},"outputs":[],"source":["%run src/q1_memory.py\n","%run src/q1_time.py\n","%run src/q2_memory.py\n","%run src/q2_time.py\n","%run src/q3_memory.py\n","%run src/q3_time.py\n","%run src/utilidades.py"]},{"cell_type":"markdown","metadata":{"id":"4QkIv7FzG_i1"},"source":["Define las funciones time call y memory_call para modularizar las llamadas de las funciones y las respuesta, evitando la repetición de codigo"]},{"cell_type":"code","source":["# line_profiler y memory_profiler\n","import line_profiler\n","from memory_profiler import profile\n","from memory_profiler import memory_usage\n","\n","# definición de la función time_call para el registro de tiempos\n","@time_it\n","def time_call(function, file_path):\n","    \"\"\"\n","    Perfila el tiempo de ejecución de la función especificada usando line_profiler y devuelve su resultado.\n","\n","    Args:\n","        function (callable): Función a perfilar.\n","        file_path (str): Ruta del archivo que procesará la función.\n","\n","    Returns:\n","        Any: Resultado de la función perfilada.\n","    \"\"\"\n","    from line_profiler import LineProfiler\n","\n","    # Crear una nueva instancia del perfilador para evitar unificar todo el log de hits\n","    profiler = LineProfiler()\n","\n","    # Agregar explícitamente la función al perfilador\n","    profiler.add_function(function)\n","\n","    # Usar un diccionario para capturar las variables locales\n","    local_vars = {\"file_path\": file_path, \"result\": None, \"function\": function}\n","\n","    # Ejecutar y perfilar la función\n","    profiler.runctx(\"result = function(file_path)\", globals(), local_vars)\n","\n","    # Mostrar estadísticas del perfilador\n","    print(f\"=== Estadísticas de Line Profiler para {function.__name__} ===\")\n","    profiler.print_stats()\n","    print(\"=== Fin de las Estadísticas ===\")\n","\n","    # Retornar el resultado de la función\n","    return local_vars[\"result\"]\n","\n","\n","# definición de la función memory_call para el registro de memoria\n","@time_it\n","def memory_call(function, file_path):\n","    \"\"\"\n","    Perfila el uso de memoria de la función especificada y devuelve su resultado.\n","\n","    Args:\n","        function_name (callable): Función a perfilar.\n","        file_path (str): Ruta del archivo que procesará la función.\n","\n","    Returns:\n","        Any: Resultado de la función perfilada.\n","    \"\"\"\n","    def wrapper():\n","        return function(file_path)\n","\n","    # Perfilar memoria usando memory_usage\n","    mem_usage, result = memory_usage(wrapper, retval=True, interval=0.1)\n","\n","    # Mostrar estadísticas de memoria\n","    print(\"=== Estadísticas de Memory Profiler ===\")\n","    print(f\"Uso máximo de memoria: {max(mem_usage):.2f} MiB\")\n","    print(f\"Uso inicial de memoria: {mem_usage[0]:.2f} MiB\")\n","    print(f\"Uso final de memoria: {mem_usage[-1]:.2f} MiB\")\n","    print(\"=== Fin de las Estadísticas ===\")\n","\n","    return result"],"metadata":{"id":"qt_I6_YIPzhd","executionInfo":{"status":"ok","timestamp":1733704837543,"user_tz":180,"elapsed":4,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["Las top 10 fechas donde hay más tweets más el usuario (username) con más tweets y su cantidad"],"metadata":{"id":"kL0SDe3gNcfr"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23622,"status":"ok","timestamp":1733704861162,"user":{"displayName":"Bastián Jofré","userId":"01444947171289054730"},"user_tz":180},"id":"ERGytV_UtnK2","outputId":"95f1b099-2b57-47cc-afae-12cb3809a538"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estadísticas de Line Profiler para q1_time ===\n","Timer unit: 1e-09 s\n","\n","Total time: 23.1944 s\n","File: /content/drive/My Drive/latam-tw-test/tw-latam-test-project/src/q1_time.py\n","Function: q1_time at line 7\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     7                                           def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n","     8                                               # Diccionario para almacenar el conteo de tweets por fecha y usuario\n","     9         1       7055.0   7055.0      0.0      tweet_count_by_date_user = defaultdict(lambda: defaultdict(int))\n","    10         1        545.0    545.0      0.0      chunksize = 10000  # Leer 10,000 líneas a la vez\n","    11                                           \n","    12         1       1007.0   1007.0      0.0      def process_chunk(chunk):\n","    13                                                   # Convertir la columna 'date' a datetime y extraer 'username'\n","    14                                                   chunk['date'] = pd.to_datetime(chunk['date']).dt.date\n","    15                                                   chunk['username'] = chunk['user'].apply(lambda x: x.get('username') if isinstance(x, dict) else None)\n","    16                                           \n","    17                                                   # Agrupar por fecha y usuario y contar tweets\n","    18                                                   grouped = chunk.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n","    19                                                   for _, row in grouped.iterrows():\n","    20                                                       tweet_count_by_date_user[row['date']][row['username']] += row['tweet_count']\n","    21                                           \n","    22         2    3666423.0    2e+06      0.0      with open(file_path, 'r', encoding='utf-8') as file:\n","    23         1       1247.0   1247.0      0.0          lines = []\n","    24    117408 3738612800.0  31842.9     16.1          for line in file:\n","    25                                                       # Cargar cada línea como un objeto JSON usando orjson\n","    26    117407 6296197147.0  53627.1     27.1              lines.append(orjson.loads(line))\n","    27    117407  107746047.0    917.7      0.5              if len(lines) >= chunksize:\n","    28                                                           # Convertir las líneas cargadas en un DataFrame de pandas\n","    29        11 2280015001.0    2e+08      9.8                  chunk = pd.DataFrame(lines)\n","    30                                                           # Procesar el chunk para contar los tweets por fecha y usuario\n","    31        11 9954113831.0    9e+08     42.9                  process_chunk(chunk)\n","    32                                                           # Reiniciar la lista de líneas\n","    33        11  180112786.0    2e+07      0.8                  lines = []\n","    34         1       1676.0   1676.0      0.0          if lines:\n","    35                                                       # Procesar el último chunk si hay líneas restantes\n","    36         1  182057863.0    2e+08      0.8              chunk = pd.DataFrame(lines)\n","    37         1  440875116.0    4e+08      1.9              process_chunk(chunk)\n","    38                                           \n","    39                                               # Preparar el resultado con el usuario más frecuente por fecha\n","    40         1       1524.0   1524.0      0.0      result = []\n","    41        14      21799.0   1557.1      0.0      for date, users in tweet_count_by_date_user.items():\n","    42                                                   # Seleccionar el usuario con más tweets para esa fecha\n","    43        13   10885017.0 837309.0      0.0          most_frequent_user = max(users, key=users.get)\n","    44        13      34714.0   2670.3      0.0          result.append((date, most_frequent_user, users[most_frequent_user]))\n","    45                                           \n","    46         1        551.0    551.0      0.0      return result\n","\n","=== Fin de las Estadísticas ===\n","⏱️ Tiempo de ejecución de time_call: 23.5418 segundos\n","Resultado final: [(datetime.date(2021, 2, 23), 'Surrypuria', 135), (datetime.date(2021, 2, 24), 'preetysaini321', 107), (datetime.date(2021, 2, 21), 'Surrypuria', 161), (datetime.date(2021, 2, 22), 'preetysaini321', 110), (datetime.date(2021, 2, 20), 'MangalJ23056160', 108), (datetime.date(2021, 2, 19), 'Preetm91', 267), (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 195), (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 185), (datetime.date(2021, 2, 16), 'jot__b', 133), (datetime.date(2021, 2, 15), 'jot__b', 134), (datetime.date(2021, 2, 14), 'rebelpacifist', 119), (datetime.date(2021, 2, 13), 'MaanDee08215437', 178), (datetime.date(2021, 2, 12), 'RanbirS00614606', 176)]\n"]}],"source":["# Llamada a 10 fechas con mayor cantidad de tweets y el usuario traves de la funcion time_call con la estadistica de tiempo de ejecucion\n","top_tweets_time = time_call(q1_time, file_path)\n","print(f\"Resultado final: {top_tweets_time}\")"]},{"cell_type":"markdown","metadata":{"id":"zQw24OyGG_i2"},"source":["Los top 10 emojis más usados con su respectivo conteo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnCnFLx7G_i2"},"outputs":[],"source":["# Llama a la funcion q2_time a traves de time_call para obtener la estadistica de tiempo en el proceso de busqueda de los top 10 emojis\n","top_emojis_time_valor = time_call(q2_time, file_path)\n","print(f\"Resultado final: {top_emojis_time_valor}\")"]},{"cell_type":"markdown","source":["El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos"],"metadata":{"id":"3BpLZKJ3R-cM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-hWEgzxG_i2"},"outputs":[],"source":["# Llama a la funcion q3_time a traves de time_call para obtener la estadistica de tiempo\n","# Proceso de busqueda de los usuarios mas influyentes\n","top_mentions_time = time_call(q3_time, file_path)\n","print(f\"Resultado final: {top_mentions_time}\")"]},{"cell_type":"markdown","source":["Las top 10 fechas donde hay más tweets más el usuario (username) con más tweets y su cantidad"],"metadata":{"id":"dmdNsqJNScc7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iT2D6Whs6o-i"},"outputs":[],"source":["# Llamada a 10 fechas con mayor cantidad de tweets y el usuario traves de la funcion memory_call con la estadistica de memoria utilizada\n","top_tweets_memory = memory_call(q1_memory, file_path)\n","print(f\"Resultado final: {top_tweets_memory}\")"]},{"cell_type":"markdown","source":["Los top 10 emojis más usados con su respectivo conteo"],"metadata":{"id":"WAuKOsGjSFhe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3W4jmu8o8_fR"},"outputs":[],"source":["# Llama a la funcion q2_memory a traves de la función memory cal para obtener la estadistica de memoria en el proceso busqueda top emojis\n","top_emoji_memory = memory_call(q2_memory, file_path)\n","print(f\"Resultado final: {top_emoji_memory}\")"]},{"cell_type":"markdown","source":["El top 10 histórico de usuarios (username) más influyentes en función del conteo de las menciones (@) que registra cada uno de ellos"],"metadata":{"id":"hIhzkqQNR391"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtDP3TDS8_nE"},"outputs":[],"source":["# Llama a la funcion q3_memory a traves de la función memory cal para obtener la estadistica de memoria en el proceso busqueda top mentions\n","top_mentions_time = memory_call(q3_memory, file_path)\n","print(f\"Resultado final: {top_mentions_time}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}