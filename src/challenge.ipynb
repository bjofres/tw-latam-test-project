{"cells":[{"cell_type":"markdown","metadata":{"id":"atWG72RrG_i0"},"source":["En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":285,"status":"ok","timestamp":1733620426695,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"PzFf8t6MrtBe","outputId":"e57e6ee7-e790-4b2a-9826-58c869615427"},"outputs":[{"output_type":"stream","name":"stdout","text":["IPython autoreload activated\n"]}],"source":["# Enable automatic reloading of modules in Jupyter Notebook (improves development workflow)\n","%reload_ext autoreload\n","\n","# Automatically restart the kernel whenever the source code changes\n","# (Provides a clean development environment)\n","%autoreload 2\n","\n","print(\"IPython autoreload activated\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1733620480098,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"YkaR33TpH0uO","outputId":"2f3eee8a-780e-4266-b23e-1e501acb0935"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project\n"]}],"source":["cd /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project"]},{"cell_type":"markdown","source":[],"metadata":{"id":"K1NDtP_p1QLG"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2735,"status":"ok","timestamp":1733620490163,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"E0PPgzitHLwq","outputId":"18a804ad-a19b-4cf0-8d0a-b8c94935b292"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Montar Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5501,"status":"ok","timestamp":1733620497483,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"CzaS8pyBN-71","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7a41d31-1f0c-4cd7-aae8-551d3f954234"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting memory-profiler==0.61.0 (from -r requirements.txt (line 1))\n","  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n","Collecting emoji==2.14.0 (from -r requirements.txt (line 2))\n","  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: gdown==5.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (5.2.0)\n","Collecting line_profiler==4.2.0 (from -r requirements.txt (line 5))\n","  Downloading line_profiler-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from memory-profiler==0.61.0->-r requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (3.16.1)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown==5.2.0->-r requirements.txt (line 3)) (4.66.6)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown==5.2.0->-r requirements.txt (line 3)) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (2024.8.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown==5.2.0->-r requirements.txt (line 3)) (1.7.1)\n","Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n","Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading line_profiler-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (718 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: memory-profiler, line_profiler, emoji\n","Successfully installed emoji-2.14.0 line_profiler-4.2.0 memory-profiler-0.61.0\n"]}],"source":["# Librer√≠as e infraestructura necesaria\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12087,"status":"ok","timestamp":1733620524041,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"2tZbFVCFJE0f","outputId":"9b612304-aea5-4bdc-af31-ad9cb3fded60"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\n","From (redirected): https://drive.google.com/uc?id=1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis&confirm=t&uuid=d64ab3bb-1069-4fda-a701-8e139aef349c\n","To: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/tweets.json.zip\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 60.4M/60.4M [00:01<00:00, 45.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Archivo descomprimido en la carpeta 'tweets_extracted'\n"]}],"source":["import gdown\n","import zipfile\n","\n","# ID del archivo (extra√≠do del enlace)\n","file_id = \"1ig2ngoXFTxP5Pa8muXo02mDTFexZzsis\"\n","# URL de descarga\n","download_url = f\"https://drive.google.com/uc?id={file_id}\"\n","# Nombre del archivo descargado\n","zip_output = \"tweets.json.zip\"\n","\n","# Descargar el archivo\n","gdown.download(download_url, zip_output, quiet=False)\n","\n","# Descomprimir el archivo\n","with zipfile.ZipFile(zip_output, 'r') as zip_ref:\n","    zip_ref.extractall(\"tweets_extracted\")\n","\n","print(\"Archivo descomprimido en la carpeta 'tweets_extracted'\")"]},{"cell_type":"markdown","metadata":{"id":"tW9HLdqpG_i0"},"source":["Se importan los modulos python junto con sus funciones  "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2890,"status":"ok","timestamp":1733620541033,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"9bZ-GGURMeaA"},"outputs":[],"source":["%run src/q1_memory.py\n","%run src/q1_time.py\n","%run src/q2_memory.py\n","%run src/q2_time.py\n","%run src/q3_memory.py\n","%run src/q3_time.py\n","%run src/utilidades.py\n"]},{"cell_type":"markdown","metadata":{"id":"nMFLEQybG_i1"},"source":["Se definen variables de entorno"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":253,"status":"ok","timestamp":1733620546413,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"Y6PR_7iNG_i1","outputId":"0039e642-2d77-43d9-9d5d-b8a4643fd9cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/tweets_extracted/farmers-protest-tweets-2021-2-4.json\n"]}],"source":["# define la ruta\n","file_directory = '/content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/tweets_extracted/'\n","\n","# define nombre de archivo\n","file_name = 'farmers-protest-tweets-2021-2-4.json'\n","\n","# concatenamos la ruta y el nombre del archivo\n","file_path = file_directory + file_name\n","print(file_path)"]},{"cell_type":"markdown","metadata":{"id":"4QkIv7FzG_i1"},"source":["Ejecuci√≥n de la llamada de cantidad de twits en un periodo \"q1_time\""]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":870,"status":"ok","timestamp":1733625515313,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"3mXhVgV-G_i1"},"outputs":[],"source":["# Usar line_profiler y memory_profiler\n","import line_profiler\n","from memory_profiler import profile  # Decorador para perfilar memoria\n","from memory_profiler import memory_usage\n","\n","@time_it\n","def time_call(profiler, function, file_path):\n","    \"\"\"\n","    Perfila el tiempo de ejecuci√≥n de la funci√≥n especificada usando line_profiler y devuelve su resultado.\n","\n","    Args:\n","        profiler (LineProfiler): Instancia de line_profiler para perfilar la funci√≥n.\n","        function (callable): Funci√≥n a perfilar.\n","        file_path (str): Ruta del archivo que procesar√° la funci√≥n.\n","\n","    Returns:\n","        Any: Resultado de la funci√≥n perfilada.\n","    \"\"\"\n","    # Agregar expl√≠citamente la funci√≥n al perfilador\n","    profiler.add_function(function)\n","\n","    # Usar un diccionario para capturar las variables locales\n","    local_vars = {\"file_path\": file_path, \"result\": None, \"function\": function}\n","\n","    # Ejecutar y perfilar la funci√≥n\n","    profiler.runctx(\"result = function(file_path)\", globals(), local_vars)\n","\n","    # Mostrar estad√≠sticas del perfilador\n","    print(\"=== Estad√≠sticas de Line Profiler ===\")\n","    profiler.print_stats()\n","    print(\"=== Fin de las Estad√≠sticas ===\")\n","\n","    # Retornar el resultado de la funci√≥n\n","    return local_vars[\"result\"]\n","\n","@time_it\n","def memory_call(function, file_path):\n","    \"\"\"\n","    Perfila el uso de memoria de la funci√≥n especificada y devuelve su resultado.\n","\n","    Args:\n","        function_name (callable): Funci√≥n a perfilar.\n","        file_path (str): Ruta del archivo que procesar√° la funci√≥n.\n","\n","    Returns:\n","        Any: Resultado de la funci√≥n perfilada.\n","    \"\"\"\n","    def wrapper():\n","        return function(file_path)\n","\n","    # Perfilar memoria usando memory_usage\n","    mem_usage, result = memory_usage(wrapper, retval=True, interval=0.1)\n","\n","    # Mostrar estad√≠sticas de memoria\n","    print(\"=== Estad√≠sticas de Memory Profiler ===\")\n","    print(f\"Uso m√°ximo de memoria: {max(mem_usage):.2f} MiB\")\n","    print(f\"Uso inicial de memoria: {mem_usage[0]:.2f} MiB\")\n","    print(f\"Uso final de memoria: {mem_usage[-1]:.2f} MiB\")\n","    print(\"=== Fin de las Estad√≠sticas ===\")\n","\n","    return result\n"]},{"cell_type":"code","source":[],"metadata":{"id":"2RAXtm3752-y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":268,"status":"ok","timestamp":1733620554019,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"urIxMXU40Eg3"},"outputs":[],"source":["profiler = line_profiler.LineProfiler()"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19337,"status":"ok","timestamp":1733625539563,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"ERGytV_UtnK2","outputId":"6496a173-b366-49f7-8841-6fd75ea70212"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Line Profiler ===\n","Timer unit: 1e-09 s\n","\n","Total time: 38.9569 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q1_time.py\n","Function: q1_time at line 6\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     6                                           def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n","     7         2       9989.0   4994.5      0.0      tweet_count_by_date_user = defaultdict(lambda: defaultdict(int))\n","     8                                           \n","     9                                               # Usamos chunksize para leer el archivo en trozos m√°s peque√±os\n","    10         2       2489.0   1244.5      0.0      chunksize = 10000  # Por ejemplo, leemos 10,000 l√≠neas a la vez\n","    11        26        2e+10    9e+08     60.4      for chunk in pd.read_json(file_path, lines=True, chunksize=chunksize):\n","    12                                                   # Convertir la columna 'date' a datetime\n","    13        24  791921195.0    3e+07      2.0          chunk['date'] = pd.to_datetime(chunk['date']).dt.date\n","    14                                           \n","    15                                                   # Extraer 'username'\n","    16        24  338998499.0    1e+07      0.9          chunk['username'] = chunk['user'].apply(lambda x: x.get('username') if isinstance(x, dict) else None)\n","    17                                           \n","    18                                                   # Agrupar por fecha y usuario y actualizar el contador\n","    19        24  358272821.0    1e+07      0.9          grouped = chunk.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n","    20    112960        1e+10  92963.8     27.0          for _, row in grouped.iterrows():\n","    21    112936 3408462782.0  30180.5      8.7              tweet_count_by_date_user[row['date']][row['username']] += row['tweet_count']\n","    22                                           \n","    23                                               # Preparar el resultado con el usuario m√°s frecuente por fecha\n","    24         2       2790.0   1395.0      0.0      result = []\n","    25        28      45032.0   1608.3      0.0      for date, users in tweet_count_by_date_user.items():\n","    26        26   27562729.0    1e+06      0.1          most_frequent_user = max(users, key=users.get)\n","    27        26      71408.0   2746.5      0.0          result.append((date, most_frequent_user, users[most_frequent_user]))\n","    28                                           \n","    29         2       1083.0    541.5      0.0      return result\n","\n","Total time: 22.3963 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q2_time.py\n","Function: q2_time at line 14\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    14                                           def q2_time(file_path: str) -> List[Tuple[str, int]]:\n","    15         2  111946827.0    6e+07      0.5      with open(file_path, 'r', encoding='utf-8') as file:\n","    16         1        664.0    664.0      0.0          tweets = []\n","    17    117408 1428901565.0  12170.4      6.4          for line in file:\n","    18    117407   35477223.0    302.2      0.2              try:\n","    19                                                           # si cada linea en el archivo es un objeto JSON por si mismo, este c√≥digo maneja la lectura\n","    20    117407 9019889952.0  76825.8     40.3                  tweet = json.loads(line) \n","    21                                                           # agrega el nuevo objeto json al arreglo \"tweets\" para posteriormente evaluarlo\n","    22    117407   70021122.0    596.4      0.3                  tweets.append(tweet)\n","    23                                                       except json.JSONDecodeError:\n","    24                                                           print(f\"Error en la l√≠nea: {line}\")  # maneja errores si alguna l√≠nea no es JSON\n","    25                                           \n","    26                                               # inicializamos un contador para los emojis\n","    27         1      20587.0  20587.0      0.0      emoji_counter = Counter()\n","    28                                           \n","    29                                               # procesamos cada tweet y extraemos los emojis\n","    30    117408   62554500.0    532.8      0.3      for tweet in tweets:\n","    31    117407  116820076.0    995.0      0.5          content = tweet.get('content', '')  # ajusta el nombre de la clave si es diferente (ej. 'text')\n","    32                                                   \n","    33                                                   # extraer emojis del contenido del tweet\n","    34    117407        1e+10  95672.2     50.2          emojis_in_tweet = extract_emojis(content)\n","    35                                                   \n","    36                                                   # contar los emojis extra√≠dos\n","    37    117407  317692009.0   2705.9      1.4          emoji_counter.update(emojis_in_tweet)\n","    38                                           \n","    39                                               # devolvemos los 10 emojis m√°s comunes\n","    40         1     392897.0 392897.0      0.0      return emoji_counter.most_common(10)\n","\n","Total time: 15.954 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q3_time.py\n","Function: q3_time at line 13\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    13                                           def q3_time(file_path: str) -> List[Tuple[str, int]]:\n","    14                                               # inicia un collection de contador para menciones\n","    15         2      26696.0  13348.0      0.0      mention_counter = Counter()\n","    16                                           \n","    17                                               # carga tweets del archivo JSON l√≠nea por l√≠nea\n","    18         4  118238892.0    3e+07      0.7      with open(file_path, 'r', encoding='utf-8') as file:\n","    19    234816 3050902701.0  12992.7     19.1          for line in file:\n","    20    234814   65586181.0    279.3      0.4              try:\n","    21    234814        1e+10  45521.8     67.0                  tweet = json.loads(line)  # cargar cada l√≠nea como un objeto JSON\n","    22    234814  175596415.0    747.8      1.1                  content = tweet.get('content', '')  # obtener el contenido del tweet\n","    23    234814 1017830329.0   4334.6      6.4                  mentions = extract_mentions(content)  # extrae menciones\n","    24    234814  814157585.0   3467.2      5.1                  mention_counter.update(mentions)  # actualiza contador\n","    25                                                       except json.JSONDecodeError:\n","    26                                                           print(f\"Error al procesar una l√≠nea: {line}\")\n","    27                                           \n","    28                                               # retorna el top 10 de menciones\n","    29         2   22547321.0    1e+07      0.1      return mention_counter.most_common(10)\n","\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de time_call: 19.0817 segundos\n","Resultado final: [(datetime.date(2021, 2, 23), 'Surrypuria', 135), (datetime.date(2021, 2, 24), 'preetysaini321', 107), (datetime.date(2021, 2, 21), 'Surrypuria', 161), (datetime.date(2021, 2, 22), 'preetysaini321', 110), (datetime.date(2021, 2, 20), 'MangalJ23056160', 108), (datetime.date(2021, 2, 19), 'Preetm91', 267), (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 195), (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 185), (datetime.date(2021, 2, 16), 'jot__b', 133), (datetime.date(2021, 2, 15), 'jot__b', 134), (datetime.date(2021, 2, 14), 'rebelpacifist', 119), (datetime.date(2021, 2, 13), 'MaanDee08215437', 178), (datetime.date(2021, 2, 12), 'RanbirS00614606', 176)]\n"]}],"source":["top_tweets_time = time_call(profiler, q1_time, file_path)\n","print(f\"Resultado final: {top_tweets_time}\")"]},{"cell_type":"markdown","metadata":{"id":"zQw24OyGG_i2"},"source":["Ejecuci√≥n de llamada top emojis - 10 mas usados"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24050,"status":"ok","timestamp":1733625563611,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"RnCnFLx7G_i2","outputId":"05faa2e3-3dfd-4886-f859-37f0dad5fd7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Line Profiler ===\n","Timer unit: 1e-09 s\n","\n","Total time: 38.9569 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q1_time.py\n","Function: q1_time at line 6\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     6                                           def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n","     7         2       9989.0   4994.5      0.0      tweet_count_by_date_user = defaultdict(lambda: defaultdict(int))\n","     8                                           \n","     9                                               # Usamos chunksize para leer el archivo en trozos m√°s peque√±os\n","    10         2       2489.0   1244.5      0.0      chunksize = 10000  # Por ejemplo, leemos 10,000 l√≠neas a la vez\n","    11        26        2e+10    9e+08     60.4      for chunk in pd.read_json(file_path, lines=True, chunksize=chunksize):\n","    12                                                   # Convertir la columna 'date' a datetime\n","    13        24  791921195.0    3e+07      2.0          chunk['date'] = pd.to_datetime(chunk['date']).dt.date\n","    14                                           \n","    15                                                   # Extraer 'username'\n","    16        24  338998499.0    1e+07      0.9          chunk['username'] = chunk['user'].apply(lambda x: x.get('username') if isinstance(x, dict) else None)\n","    17                                           \n","    18                                                   # Agrupar por fecha y usuario y actualizar el contador\n","    19        24  358272821.0    1e+07      0.9          grouped = chunk.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n","    20    112960        1e+10  92963.8     27.0          for _, row in grouped.iterrows():\n","    21    112936 3408462782.0  30180.5      8.7              tweet_count_by_date_user[row['date']][row['username']] += row['tweet_count']\n","    22                                           \n","    23                                               # Preparar el resultado con el usuario m√°s frecuente por fecha\n","    24         2       2790.0   1395.0      0.0      result = []\n","    25        28      45032.0   1608.3      0.0      for date, users in tweet_count_by_date_user.items():\n","    26        26   27562729.0    1e+06      0.1          most_frequent_user = max(users, key=users.get)\n","    27        26      71408.0   2746.5      0.0          result.append((date, most_frequent_user, users[most_frequent_user]))\n","    28                                           \n","    29         2       1083.0    541.5      0.0      return result\n","\n","Total time: 45.3052 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q2_time.py\n","Function: q2_time at line 14\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    14                                           def q2_time(file_path: str) -> List[Tuple[str, int]]:\n","    15         4  173164442.0    4e+07      0.4      with open(file_path, 'r', encoding='utf-8') as file:\n","    16         2       3030.0   1515.0      0.0          tweets = []\n","    17    234816 3041730798.0  12953.7      6.7          for line in file:\n","    18    234814   72452111.0    308.6      0.2              try:\n","    19                                                           # si cada linea en el archivo es un objeto JSON por si mismo, este c√≥digo maneja la lectura\n","    20    234814        2e+10  77754.6     40.3                  tweet = json.loads(line) \n","    21                                                           # agrega el nuevo objeto json al arreglo \"tweets\" para posteriormente evaluarlo\n","    22    234814  148685331.0    633.2      0.3                  tweets.append(tweet)\n","    23                                                       except json.JSONDecodeError:\n","    24                                                           print(f\"Error en la l√≠nea: {line}\")  # maneja errores si alguna l√≠nea no es JSON\n","    25                                           \n","    26                                               # inicializamos un contador para los emojis\n","    27         2      40904.0  20452.0      0.0      emoji_counter = Counter()\n","    28                                           \n","    29                                               # procesamos cada tweet y extraemos los emojis\n","    30    234816  129773653.0    552.7      0.3      for tweet in tweets:\n","    31    234814  243414449.0   1036.6      0.5          content = tweet.get('content', '')  # ajusta el nombre de la clave si es diferente (ej. 'text')\n","    32                                                   \n","    33                                                   # extraer emojis del contenido del tweet\n","    34    234814        2e+10  96210.2     49.9          emojis_in_tweet = extract_emojis(content)\n","    35                                                   \n","    36                                                   # contar los emojis extra√≠dos\n","    37    234814  645761426.0   2750.1      1.4          emoji_counter.update(emojis_in_tweet)\n","    38                                           \n","    39                                               # devolvemos los 10 emojis m√°s comunes\n","    40         2     779206.0 389603.0      0.0      return emoji_counter.most_common(10)\n","\n","Total time: 15.954 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q3_time.py\n","Function: q3_time at line 13\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    13                                           def q3_time(file_path: str) -> List[Tuple[str, int]]:\n","    14                                               # inicia un collection de contador para menciones\n","    15         2      26696.0  13348.0      0.0      mention_counter = Counter()\n","    16                                           \n","    17                                               # carga tweets del archivo JSON l√≠nea por l√≠nea\n","    18         4  118238892.0    3e+07      0.7      with open(file_path, 'r', encoding='utf-8') as file:\n","    19    234816 3050902701.0  12992.7     19.1          for line in file:\n","    20    234814   65586181.0    279.3      0.4              try:\n","    21    234814        1e+10  45521.8     67.0                  tweet = json.loads(line)  # cargar cada l√≠nea como un objeto JSON\n","    22    234814  175596415.0    747.8      1.1                  content = tweet.get('content', '')  # obtener el contenido del tweet\n","    23    234814 1017830329.0   4334.6      6.4                  mentions = extract_mentions(content)  # extrae menciones\n","    24    234814  814157585.0   3467.2      5.1                  mention_counter.update(mentions)  # actualiza contador\n","    25                                                       except json.JSONDecodeError:\n","    26                                                           print(f\"Error al procesar una l√≠nea: {line}\")\n","    27                                           \n","    28                                               # retorna el top 10 de menciones\n","    29         2   22547321.0    1e+07      0.1      return mention_counter.most_common(10)\n","\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de time_call: 23.9566 segundos\n","Resultado final: [('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"]}],"source":["# Call q2_time and print the result\n","top_emojis_time_valor = time_call(profiler, q2_time, file_path)\n","print(f\"Resultado final: {top_emojis_time_valor}\")"]},{"cell_type":"markdown","metadata":{"id":"p9tyU8PSG_i2"},"source":["Ejecuci√≥n de llamada de tweets con m√°s reacciones"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9090,"status":"ok","timestamp":1733625577040,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"r-hWEgzxG_i2","outputId":"54706c27-0268-4f39-d4ea-41067979b98f"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Line Profiler ===\n","Timer unit: 1e-09 s\n","\n","Total time: 38.9569 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q1_time.py\n","Function: q1_time at line 6\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","     6                                           def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n","     7         2       9989.0   4994.5      0.0      tweet_count_by_date_user = defaultdict(lambda: defaultdict(int))\n","     8                                           \n","     9                                               # Usamos chunksize para leer el archivo en trozos m√°s peque√±os\n","    10         2       2489.0   1244.5      0.0      chunksize = 10000  # Por ejemplo, leemos 10,000 l√≠neas a la vez\n","    11        26        2e+10    9e+08     60.4      for chunk in pd.read_json(file_path, lines=True, chunksize=chunksize):\n","    12                                                   # Convertir la columna 'date' a datetime\n","    13        24  791921195.0    3e+07      2.0          chunk['date'] = pd.to_datetime(chunk['date']).dt.date\n","    14                                           \n","    15                                                   # Extraer 'username'\n","    16        24  338998499.0    1e+07      0.9          chunk['username'] = chunk['user'].apply(lambda x: x.get('username') if isinstance(x, dict) else None)\n","    17                                           \n","    18                                                   # Agrupar por fecha y usuario y actualizar el contador\n","    19        24  358272821.0    1e+07      0.9          grouped = chunk.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n","    20    112960        1e+10  92963.8     27.0          for _, row in grouped.iterrows():\n","    21    112936 3408462782.0  30180.5      8.7              tweet_count_by_date_user[row['date']][row['username']] += row['tweet_count']\n","    22                                           \n","    23                                               # Preparar el resultado con el usuario m√°s frecuente por fecha\n","    24         2       2790.0   1395.0      0.0      result = []\n","    25        28      45032.0   1608.3      0.0      for date, users in tweet_count_by_date_user.items():\n","    26        26   27562729.0    1e+06      0.1          most_frequent_user = max(users, key=users.get)\n","    27        26      71408.0   2746.5      0.0          result.append((date, most_frequent_user, users[most_frequent_user]))\n","    28                                           \n","    29         2       1083.0    541.5      0.0      return result\n","\n","Total time: 45.3052 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q2_time.py\n","Function: q2_time at line 14\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    14                                           def q2_time(file_path: str) -> List[Tuple[str, int]]:\n","    15         4  173164442.0    4e+07      0.4      with open(file_path, 'r', encoding='utf-8') as file:\n","    16         2       3030.0   1515.0      0.0          tweets = []\n","    17    234816 3041730798.0  12953.7      6.7          for line in file:\n","    18    234814   72452111.0    308.6      0.2              try:\n","    19                                                           # si cada linea en el archivo es un objeto JSON por si mismo, este c√≥digo maneja la lectura\n","    20    234814        2e+10  77754.6     40.3                  tweet = json.loads(line) \n","    21                                                           # agrega el nuevo objeto json al arreglo \"tweets\" para posteriormente evaluarlo\n","    22    234814  148685331.0    633.2      0.3                  tweets.append(tweet)\n","    23                                                       except json.JSONDecodeError:\n","    24                                                           print(f\"Error en la l√≠nea: {line}\")  # maneja errores si alguna l√≠nea no es JSON\n","    25                                           \n","    26                                               # inicializamos un contador para los emojis\n","    27         2      40904.0  20452.0      0.0      emoji_counter = Counter()\n","    28                                           \n","    29                                               # procesamos cada tweet y extraemos los emojis\n","    30    234816  129773653.0    552.7      0.3      for tweet in tweets:\n","    31    234814  243414449.0   1036.6      0.5          content = tweet.get('content', '')  # ajusta el nombre de la clave si es diferente (ej. 'text')\n","    32                                                   \n","    33                                                   # extraer emojis del contenido del tweet\n","    34    234814        2e+10  96210.2     49.9          emojis_in_tweet = extract_emojis(content)\n","    35                                                   \n","    36                                                   # contar los emojis extra√≠dos\n","    37    234814  645761426.0   2750.1      1.4          emoji_counter.update(emojis_in_tweet)\n","    38                                           \n","    39                                               # devolvemos los 10 emojis m√°s comunes\n","    40         2     779206.0 389603.0      0.0      return emoji_counter.most_common(10)\n","\n","Total time: 8.41214 s\n","File: /content/drive/MyDrive/tw-latam-test-b/tw-latam-test-project/src/q3_time.py\n","Function: q3_time at line 13\n","\n","Line #      Hits         Time  Per Hit   % Time  Line Contents\n","==============================================================\n","    13                                           def q3_time(file_path: str) -> List[Tuple[str, int]]:\n","    14                                               # inicia un collection de contador para menciones\n","    15         1      11515.0  11515.0      0.0      mention_counter = Counter()\n","    16                                           \n","    17                                               # carga tweets del archivo JSON l√≠nea por l√≠nea\n","    18         2   58418645.0    3e+07      0.7      with open(file_path, 'r', encoding='utf-8') as file:\n","    19    117408 1628266558.0  13868.4     19.4          for line in file:\n","    20    117407   37186165.0    316.7      0.4              try:\n","    21    117407 5631969329.0  47969.6     67.0                  tweet = json.loads(line)  # cargar cada l√≠nea como un objeto JSON\n","    22    117407   92232125.0    785.6      1.1                  content = tweet.get('content', '')  # obtener el contenido del tweet\n","    23    117407  526134534.0   4481.3      6.3                  mentions = extract_mentions(content)  # extrae menciones\n","    24    117407  429244656.0   3656.0      5.1                  mention_counter.update(mentions)  # actualiza contador\n","    25                                                       except json.JSONDecodeError:\n","    26                                                           print(f\"Error al procesar una l√≠nea: {line}\")\n","    27                                           \n","    28                                               # retorna el top 10 de menciones\n","    29         1    8681029.0    9e+06      0.1      return mention_counter.most_common(10)\n","\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de time_call: 8.8100 segundos\n","Resultado final: [('@narendramodi', 2224), ('@Kisanektamorcha', 1829), ('@RakeshTikaitBKU', 1611), ('@PMOIndia', 1395), ('@RahulGandhi', 1106), ('@GretaThunberg', 1007), ('@RaviSinghKA', 1002), ('@UNHumanRights', 958), ('@rihanna', 951), ('@meenaharris', 915)]\n"]}],"source":["top_mentions_time = time_call(profiler, q3_time, file_path)\n","print(f\"Resultado final: {top_mentions_time}\")"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11004,"status":"ok","timestamp":1733625607931,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"iT2D6Whs6o-i","outputId":"2a82f41e-4337-4c22-cbfc-c79d20420a75"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Memory Profiler ===\n","Uso m√°ximo de memoria: 826.79 MiB\n","Uso inicial de memoria: 826.71 MiB\n","Uso final de memoria: 825.80 MiB\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de memory_call: 10.6981 segundos\n","Resultado final: [(datetime.date(2021, 2, 24), 'preetysaini321', 107), (datetime.date(2021, 2, 23), 'Surrypuria', 135), (datetime.date(2021, 2, 22), 'preetysaini321', 110), (datetime.date(2021, 2, 21), 'Surrypuria', 161), (datetime.date(2021, 2, 20), 'MangalJ23056160', 108), (datetime.date(2021, 2, 19), 'Preetm91', 267), (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 195), (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 185), (datetime.date(2021, 2, 16), 'jot__b', 133), (datetime.date(2021, 2, 15), 'jot__b', 134), (datetime.date(2021, 2, 14), 'rebelpacifist', 119), (datetime.date(2021, 2, 13), 'MaanDee08215437', 178), (datetime.date(2021, 2, 12), 'RanbirS00614606', 176)]\n"]}],"source":["top_emojis_memory = memory_call(q1_memory, file_path)\n","print(f\"Resultado final: {top_emojis_memory}\")"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11245,"status":"ok","timestamp":1733625619174,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"3W4jmu8o8_fR","outputId":"7aead384-746f-4c81-fad3-553c1800c72b"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Memory Profiler ===\n","Uso m√°ximo de memoria: 824.83 MiB\n","Uso inicial de memoria: 824.82 MiB\n","Uso final de memoria: 824.83 MiB\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de memory_call: 11.2332 segundos\n","Resultado final: [('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n"]}],"source":["top_mentions_memory = memory_call(q2_memory, file_path)\n","print(f\"Resultado final: {top_mentions_memory}\")"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5894,"status":"ok","timestamp":1733625625066,"user":{"displayName":"Basti√°n Jofr√©","userId":"01444947171289054730"},"user_tz":180},"id":"JtDP3TDS8_nE","outputId":"a251bb3c-573e-49f4-9e08-c32f4b21169e"},"outputs":[{"output_type":"stream","name":"stdout","text":["=== Estad√≠sticas de Memory Profiler ===\n","Uso m√°ximo de memoria: 822.86 MiB\n","Uso inicial de memoria: 822.86 MiB\n","Uso final de memoria: 822.86 MiB\n","=== Fin de las Estad√≠sticas ===\n","‚è±Ô∏è Tiempo de ejecuci√≥n de memory_call: 5.8867 segundos\n","Resultado final: [('@narendramodi', 2224), ('@Kisanektamorcha', 1829), ('@RakeshTikaitBKU', 1611), ('@PMOIndia', 1395), ('@RahulGandhi', 1106), ('@GretaThunberg', 1007), ('@RaviSinghKA', 1002), ('@UNHumanRights', 958), ('@rihanna', 951), ('@meenaharris', 915)]\n"]}],"source":["top_mentions_time = memory_call(q3_memory, file_path)\n","print(f\"Resultado final: {top_mentions_time}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}